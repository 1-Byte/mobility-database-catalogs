name: Export to CSV script

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.9]
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest wheel numpy
          sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable
          sudo apt-get update
          sudo apt-get install gdal-bin python3-gdal
          sudo apt-get install libgdal-dev
          pip install GDAL==$(gdal-config --version) --global-option=build_ext --global-option="-I/usr/include/gdal"
          sudo apt-get install libspatialindex-dev
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      - name: Export the GTFS catalog as CSV
        uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import pandas as pd
            import os
            import json

            GTFS_CSV_PATH = "./catalog_static_gtfs.csv"
            GTFS_CSV_COLUMNS = [
              'mdb_source_id',
              'name',
              'location',
              'country_code',
              'data_type',
              'urls.auto_discovery',
              'urls.license',
              'urls.latest',
              'bounding_box.minimum_latitude',
              'bounding_box.maximum_latitude',
              'bounding_box.minimum_longitude',
              'bounding_box.maximum_longitude'
            ]

            # tools.constants.GTFS
            GTFS = "gtfs"

            # tools.constants.GTFS_CATALOG_PATH_FROM_ROOT
            GTFS_CATALOG_PATH_FROM_ROOT = "mobility_catalogs/catalogs/static/gtfs"

            # tools.operations.get_sources
            catalog_root = os.path.join(".", GTFS_CATALOG_PATH_FROM_ROOT)
            # tools.helpers.aggregate
            catalog = []
            for path, sub_dirs, files in os.walk(catalog_root):
                for file in files:
                    with open(os.path.join(path, file)) as fp:
                        catalog.append(json.load(fp))

            # tools.helpers.to_csv
            catalog = pd.json_normalize(catalog)
            if columns is not None:
                catalog = catalog[GTFS_CSV_COLUMNS]
            catalog.to_csv(GTFS_CSV_PATH, sep=",", index=False)

      - name: Upload the GTFS Catalog CSV artifact
        uses: actions/upload-artifact@v1
        with:
          name: catalog-static-gtfs-csv-v${{ github.run_id }}.${{ github.run_number }}
          path: ./catalog_static_gtfs.csv