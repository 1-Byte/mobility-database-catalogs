name: Store latest datasets on approval

on:
  pull_request_review:
    types: [ submitted ]
    branches: [ main ]

jobs:
  get-urls:
    if: github.event.review.state == 'approved' && contains(github.event.pull_request.title, '[SOURCES]')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Download URLs matrix artifact
        uses: dawidd6/action-download-artifact@v2
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          workflow: download_latest_datasets_on_ready_for_review.yml
          workflow_conclusion: success
          pr: ${{ github.event.review.pull_request.number }}
          name: urls_matrix
      - name: Set URLs matrix
        id: set-matrix
        run: |
          DATASETS=$(jq . ./urls_matrix.json -c)
          echo $DATASETS
          echo "::set-output name=matrix::$DATASETS"
      - name: Persist URLs matrix artifact
        if: always()
        uses: actions/upload-artifact@v2
        with:
          name: urls_matrix
          path: ./urls_matrix.json
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
  download-datasets:
    needs: [ get-urls ]
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJson(needs.get-urls.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v2
      - name: Download datasets artifact
        uses: dawidd6/action-download-artifact@v2
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          workflow: download_latest_datasets_on_ready_for_review.yml
          workflow_conclusion: success
          pr: ${{ github.event.review.pull_request.number }}
          name: datasets
      - name: Persist datasets artifact
        uses: actions/upload-artifact@v2
        with:
          name: datasets
          path: datasets
  store-datasets:
    needs: [ download-datasets ]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Download datasets artifact
        uses: actions/download-artifact@master
        with:
          name: datasets
          path: datasets
      - name: Set up and authorize Cloud
        uses: google-github-actions/auth@v0
        with:
          credentials_json: ${{ secrets.ARCHIVE_DATASET_SA_KEY }}
      - name: Upload datasets to Google Cloud Storage
        id: upload-datasets
        uses: google-github-actions/upload-cloud-storage@main
        with:
          path: datasets
          destination: mdb-latest
          parent: false
  validate-latest:
    needs: [ get-urls, store-datasets ]
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJson(needs.get-urls.outputs.matrix) }}
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest wheel numpy
          sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable
          sudo apt-get update
          sudo apt-get install gdal-bin python3-gdal
          sudo apt-get install libgdal-dev
          pip install GDAL==$(gdal-config --version) --global-option=build_ext --global-option="-I/usr/include/gdal"
          sudo apt-get install libspatialindex-dev
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
      - name: Validate the latest datasets
        shell: python
        run: |
          import os
          import json
          import gtfs_kit
          import requests

          # Jobs constants
          BASE = "base"
          LATEST = "latest"

          jobs = """${{ matrix.data }}""".split()
          for job in jobs:
              job_json = json.loads(job)
              base = job_json[BASE]
              url = job_json[LATEST]

              # Make sure that the uploaded latest dataset is a readable GTFS Schedule dataset
              try:
                  gtfs_kit.read_feed(url, dist_units="km")
              except Exception as e:
                  raise Exception(
                      f"{base}: Exception {e} found while parsing the GTFS dataset with the GTFS kit library."
                      f"The dataset must be a valid GTFS zip file or URL.\n"
                  )
